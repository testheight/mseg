Time: 2023-03-24 16:00:31,642 -- INFO: epochs: 100, batch_size: 4, lr: 0.0001
Time: 2023-03-24 16:00:31,642 -- INFO: Segformer(
  (mit): MiT(
    (stages): ModuleList(
      (0): ModuleList(
        (0): Unfold(kernel_size=7, dilation=1, padding=3, stride=4)
        (1): Conv2d(147, 32, kernel_size=(1, 1), stride=(1, 1))
        (2): ModuleList(
          (0): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(32, 64, kernel_size=(8, 8), stride=(8, 8), bias=False)
                (to_out): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
          (1): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(32, 64, kernel_size=(8, 8), stride=(8, 8), bias=False)
                (to_out): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
        )
      )
      (1): ModuleList(
        (0): Unfold(kernel_size=3, dilation=1, padding=1, stride=2)
        (1): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))
        (2): ModuleList(
          (0): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
                (to_out): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
          (1): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
                (to_out): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
        )
      )
      (2): ModuleList(
        (0): Unfold(kernel_size=3, dilation=1, padding=1, stride=2)
        (1): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))
        (2): ModuleList(
          (0): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(160, 320, kernel_size=(2, 2), stride=(2, 2), bias=False)
                (to_out): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
                      (1): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
          (1): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(160, 320, kernel_size=(2, 2), stride=(2, 2), bias=False)
                (to_out): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
                      (1): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
        )
      )
      (3): ModuleList(
        (0): Unfold(kernel_size=3, dilation=1, padding=1, stride=2)
        (1): Conv2d(1440, 256, kernel_size=(1, 1), stride=(1, 1))
        (2): ModuleList(
          (0): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                      (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
          (1): ModuleList(
            (0): PreNorm(
              (fn): EfficientSelfAttention(
                (to_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_kv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (to_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              )
              (norm): LayerNorm()
            )
            (1): PreNorm(
              (fn): MixFeedForward(
                (net): Sequential(
                  (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
                  (1): DsConv2d(
                    (net): Sequential(
                      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                      (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
                    )
                  )
                  (2): GELU(approximate='none')
                  (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
                )
              )
              (norm): LayerNorm()
            )
          )
        )
      )
    )
  )
  (to_fused): ModuleList(
    (0): Sequential(
      (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Upsample(scale_factor=1.0, mode=nearest)
    )
    (1): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Upsample(scale_factor=2.0, mode=nearest)
    )
    (2): Sequential(
      (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Upsample(scale_factor=4.0, mode=nearest)
    )
    (3): Sequential(
      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Upsample(scale_factor=8.0, mode=nearest)
    )
  )
  (to_segmentation): Sequential(
    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
  )
)
Time: 2023-03-24 16:00:31,670 -- INFO: optimizer:adamw
Time: 2023-03-24 16:00:31,671 -- INFO: {'state': {}, 'param_groups': [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]}]}
Time: 2023-03-24 16:00:31,672 -- INFO: CosLR
Time: 2023-03-24 16:00:31,672 -- INFO: <function focal_loss at 0x00000290CD8491F0>
Time: 2023-03-24 16:00:33,831 -- INFO: ---Trian--- epoch: 1 [0/157 (0%)], loss: 0.087270 
Time: 2023-03-24 16:00:39,436 -- INFO: ---Trian--- epoch: 1 [4/157 (3%)], loss: 0.030182 
Time: 2023-03-24 16:00:44,805 -- INFO: ---Trian--- epoch: 1 [8/157 (5%)], loss: 0.077339 
Time: 2023-03-24 16:00:50,019 -- INFO: ---Trian--- epoch: 1 [12/157 (8%)], loss: 0.030342 
Time: 2023-03-24 16:00:55,186 -- INFO: ---Trian--- epoch: 1 [16/157 (10%)], loss: 0.031249 
Time: 2023-03-24 16:01:00,370 -- INFO: ---Trian--- epoch: 1 [20/157 (13%)], loss: 0.028948 
Time: 2023-03-24 16:01:05,756 -- INFO: ---Trian--- epoch: 1 [24/157 (15%)], loss: 0.035344 
Time: 2023-03-24 16:01:10,834 -- INFO: ---Trian--- epoch: 1 [28/157 (18%)], loss: 0.021327 
Time: 2023-03-24 16:01:16,028 -- INFO: ---Trian--- epoch: 1 [32/157 (20%)], loss: 0.033849 
Time: 2023-03-24 16:01:21,340 -- INFO: ---Trian--- epoch: 1 [36/157 (23%)], loss: 0.054351 
Time: 2023-03-24 16:01:26,522 -- INFO: ---Trian--- epoch: 1 [40/157 (25%)], loss: 0.021580 
Time: 2023-03-24 16:01:31,612 -- INFO: ---Trian--- epoch: 1 [44/157 (28%)], loss: 0.025186 
Time: 2023-03-24 16:01:36,708 -- INFO: ---Trian--- epoch: 1 [48/157 (31%)], loss: 0.022825 
Time: 2023-03-24 16:01:41,881 -- INFO: ---Trian--- epoch: 1 [52/157 (33%)], loss: 0.019248 
Time: 2023-03-24 16:01:47,207 -- INFO: ---Trian--- epoch: 1 [56/157 (36%)], loss: 0.019001 
Time: 2023-03-24 16:01:52,550 -- INFO: ---Trian--- epoch: 1 [60/157 (38%)], loss: 0.022484 
Time: 2023-03-24 16:01:57,813 -- INFO: ---Trian--- epoch: 1 [64/157 (41%)], loss: 0.019087 
Time: 2023-03-24 16:02:02,901 -- INFO: ---Trian--- epoch: 1 [68/157 (43%)], loss: 0.026707 
Time: 2023-03-24 16:02:08,191 -- INFO: ---Trian--- epoch: 1 [72/157 (46%)], loss: 0.030547 
Time: 2023-03-24 16:02:13,453 -- INFO: ---Trian--- epoch: 1 [76/157 (48%)], loss: 0.029675 
Time: 2023-03-24 16:02:18,731 -- INFO: ---Trian--- epoch: 1 [80/157 (51%)], loss: 0.034433 
Time: 2023-03-24 16:02:23,887 -- INFO: ---Trian--- epoch: 1 [84/157 (54%)], loss: 0.016207 
Time: 2023-03-24 16:02:29,084 -- INFO: ---Trian--- epoch: 1 [88/157 (56%)], loss: 0.012128 
Time: 2023-03-24 16:02:34,257 -- INFO: ---Trian--- epoch: 1 [92/157 (59%)], loss: 0.017861 
Time: 2023-03-24 16:02:39,356 -- INFO: ---Trian--- epoch: 1 [96/157 (61%)], loss: 0.015899 
Time: 2023-03-24 16:02:44,483 -- INFO: ---Trian--- epoch: 1 [100/157 (64%)], loss: 0.026788 
Time: 2023-03-24 16:02:49,629 -- INFO: ---Trian--- epoch: 1 [104/157 (66%)], loss: 0.046156 
Time: 2023-03-24 16:02:54,735 -- INFO: ---Trian--- epoch: 1 [108/157 (69%)], loss: 0.017802 
Time: 2023-03-24 16:02:59,837 -- INFO: ---Trian--- epoch: 1 [112/157 (71%)], loss: 0.019962 
Time: 2023-03-24 16:03:04,936 -- INFO: ---Trian--- epoch: 1 [116/157 (74%)], loss: 0.029862 
Time: 2023-03-24 16:03:10,055 -- INFO: ---Trian--- epoch: 1 [120/157 (76%)], loss: 0.016149 
Time: 2023-03-24 16:03:15,138 -- INFO: ---Trian--- epoch: 1 [124/157 (79%)], loss: 0.026002 
Time: 2023-03-24 16:03:20,241 -- INFO: ---Trian--- epoch: 1 [128/157 (82%)], loss: 0.016742 
Time: 2023-03-24 16:03:25,499 -- INFO: ---Trian--- epoch: 1 [132/157 (84%)], loss: 0.020490 
Time: 2023-03-24 16:03:30,628 -- INFO: ---Trian--- epoch: 1 [136/157 (87%)], loss: 0.021960 
Time: 2023-03-24 16:03:35,750 -- INFO: ---Trian--- epoch: 1 [140/157 (89%)], loss: 0.038095 
Time: 2023-03-24 16:03:40,925 -- INFO: ---Trian--- epoch: 1 [144/157 (92%)], loss: 0.031854 
Time: 2023-03-24 16:03:46,140 -- INFO: ---Trian--- epoch: 1 [148/157 (94%)], loss: 0.043989 
Time: 2023-03-24 16:03:51,265 -- INFO: ---Trian--- epoch: 1 [152/157 (97%)], loss: 0.017569 
Time: 2023-03-24 16:03:55,323 -- INFO: ---Trian--- epoch: 1 [156/157 (99%)], loss: 0.008441 
Time: 2023-03-24 16:03:58,058 -- INFO: ---Trian--- epoch: 2 [0/157 (0%)], loss: 0.016493 
Time: 2023-03-24 16:04:03,276 -- INFO: ---Trian--- epoch: 2 [4/157 (3%)], loss: 0.018237 
Time: 2023-03-24 16:04:08,508 -- INFO: ---Trian--- epoch: 2 [8/157 (5%)], loss: 0.028346 
Time: 2023-03-24 16:04:13,753 -- INFO: ---Trian--- epoch: 2 [12/157 (8%)], loss: 0.019865 
Time: 2023-03-24 16:04:19,011 -- INFO: ---Trian--- epoch: 2 [16/157 (10%)], loss: 0.030073 
