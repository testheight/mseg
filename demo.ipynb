{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)  # Log等级总开关\n",
    "log_file_abs = \"flask.log\"\n",
    " \n",
    "stream_handler = logging.StreamHandler()  # 日志控制台输出\n",
    " \n",
    "handler = logging.FileHandler(log_file_abs, mode='w', encoding='UTF-8')  # 日志文件输出\n",
    "handler.setLevel(logging.DEBUG)\n",
    " \n",
    "# 控制台输出格式\n",
    "stream_format = logging.Formatter(\"Time: %(asctime)s -- INFO: %(message)s\")\n",
    " \n",
    "# 文件输出格式\n",
    "logging_format = logging.Formatter(\"Time: %(asctime)s -- INFO: %(message)s\")\n",
    " \n",
    "handler.setFormatter(logging_format)  # 为改处理器handler 选择一个格式化器\n",
    "stream_handler.setFormatter(stream_format)\n",
    " \n",
    "logger.addHandler(handler)  # 为记录器添加 处理方式Handler\n",
    "logger.addHandler(stream_handler)\n",
    " \n",
    "logger.info(\"------logger.info-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:.6f}\".format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1():\n",
    "    print(\"function1\")\n",
    "\n",
    "def function2():\n",
    "    print(\"function2\")\n",
    "\n",
    "def function3():\n",
    "    print(\"function3\")\n",
    "\n",
    "def call_fun_by_str(fun_str):\n",
    "    eval(fun_str)()\n",
    "\n",
    "call_fun_by_str(\"function2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.rand(2,64,128,128)\n",
    "\n",
    "# y = F.interpolate(x,size=(128,128), scale_factor=None, mode='bilinear', align_corners=None, recompute_scale_factor=None)\n",
    "# print(y.shape)\n",
    "    \n",
    "trans_conv = nn.ConvTranspose2d(in_channels=64, out_channels=16,kernel_size=2, stride=2)\n",
    "y = trans_conv(x)\n",
    "print(y.shape)\n",
    "\n",
    "# pixel = nn.PixelShuffle(4)\n",
    "# y = pixel(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "model1 = smp.DeepLabV3Plus(\n",
    "        encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "\n",
    "model2 = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.nn.Conv2d(3, 256, kernel_size=7, stride=4,\n",
    "                              padding=(7 // 2, 7 // 2))\n",
    "x = torch.rand(1,3,512,512)\n",
    "y = a(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "6812336128.0\n",
      "3933346.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from model import transunet_m,swinunet_m,deeplabv3p_smp,unet_smp,segformer_m,pspnet_smp,segnet_m\n",
    "model = segformer_m()\n",
    "x = torch.randn(2, 3, 512, 512)\n",
    "flops , params = profile(model,inputs=(x,))\n",
    "print(flops)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "model_resnet = timm.list_models('*unet*')\n",
    "print(model_resnet)\n",
    "\n",
    "# # #mobilenetv3_large_075\n",
    "# net = timm.create_model('resnet101', pretrained=False,num_classes=0,global_pool='')\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseSeparableConv(\n",
      "  (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (bn1): BatchNormAct2d(\n",
      "    256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (se): Identity()\n",
      "  (conv_pw): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNormAct2d(\n",
      "    128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "torch.Size([2, 128, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timm.models.efficientnet_blocks import DepthwiseSeparableConv\n",
    "\n",
    "x = torch.rand(2,256,256,256)\n",
    "net = DepthwiseSeparableConv(256,128,3)\n",
    "print(net)\n",
    "print(net(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:171: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:32: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:306: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:344: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "d:\\software\\Code\\anaconda3\\envs\\demo1\\lib\\site-packages\\einops\\einops.py:316: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  known: Set[str] = {axis for axis in composite_axis if axis_name2known_length[axis] != _unknown_axis_length}\n",
      "d:\\software\\Code\\anaconda3\\envs\\demo1\\lib\\site-packages\\einops\\einops.py:317: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  unknown: Set[str] = {axis for axis in composite_axis if axis_name2known_length[axis] == _unknown_axis_length}\n",
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H*W, \"input features has wrong size\"\n",
      "d:\\31890\\Desktop\\codefile\\mseg\\model\\swin_unet.py:367: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch,onnx\n",
    "from model.swin_unet import swinunet_m\n",
    "\n",
    "net = swinunet_m(\n",
    "        num_classes=2\n",
    "    )\n",
    "model_name = 'net.onnx'#保存ONNX的文件名字\n",
    "dummy_input = torch.randn(1, 3, 512, 512)\n",
    "torch.onnx.export(net, dummy_input, model_name, input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae427aa2e465fffec33c51409f280a7a5059965133c80ad2f1b01fb7ca86caf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
